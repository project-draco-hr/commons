def execute_single_compilation(self, scala_targets, cp, upstream_analysis_caches):
    'Execute a single compilation, updating upstream_analysis_caches if needed.'
    self.context.log.info(('Compiling targets %s' % str(scala_targets)))
    if (len(scala_targets) == 1):
        compilation_id = scala_targets[0].id
    elif (len(self.context.target_roots) == 1):
        compilation_id = self.context.target_roots[0].id
    else:
        compilation_id = self.context.id
    depfile = (os.path.join(self._depfile_dir, compilation_id) + '.dependencies')
    if self._incremental:
        if self._flatten:
            output_dir = self._classes_dir
            analysis_cache = (os.path.join(self._analysis_cache_dir, compilation_id) + '.flat')
        else:
            output_dir = os.path.join(self._incremental_classes_dir, compilation_id)
            analysis_cache = os.path.join(self._analysis_cache_dir, compilation_id)
    else:
        output_dir = self._classes_dir
        analysis_cache = None
    if (self._incremental and self._flatten):
        invalidate_globally = True
    else:
        invalidate_globally = False
    with self.changed(scala_targets, invalidate_dependants=True, invalidate_globally=invalidate_globally) as changed_targets:
        sources_by_target = self.calculate_sources(changed_targets)
        if sources_by_target:
            sources = reduce((lambda all, sources: all.union(sources)), sources_by_target.values())
            if (not sources):
                self.context.log.warn(('Skipping scala compile for targets with no sources:\n  %s' % '\n  '.join((str(t) for t in sources_by_target.keys()))))
            else:
                classpath = [jar for (conf, jar) in cp if (conf in self._confs)]
                result = self.compile(classpath, sources, output_dir, analysis_cache, upstream_analysis_caches, depfile)
                if (result != 0):
                    raise TaskError(('%s returned %d' % (self._main, result)))
                if (output_dir != self._classes_dir):
                    for (dirpath, dirnames, filenames) in os.walk(output_dir):
                        for d in [os.path.join(dirpath, x) for x in dirnames]:
                            dir = os.path.join(self._classes_dir, os.path.relpath(d, output_dir))
                            if (not os.path.isdir(dir)):
                                os.mkdir(dir)
                        for f in [os.path.join(dirpath, x) for x in filenames]:
                            shutil.copy(f, os.path.join(self._classes_dir, os.path.relpath(f, output_dir)))
    deps = Dependencies(output_dir)
    deps.load(depfile)
    self._deps.merge(deps)
    if (self._incremental and (not self._flatten)):
        upstream_analysis_caches[output_dir] = analysis_cache
