def execute_single_compilation(self, versioned_target_set, cp, upstream_analysis_caches):
    'Execute a single compilation, updating upstream_analysis_caches if needed.'
    if self._flatten:
        compilation_id = 'flat'
        output_dir = self._flat_classes_dir
    else:
        compilation_id = Target.maybe_readable_identify(versioned_target_set.targets)
        output_dir = os.path.join(self._incremental_classes_dir, compilation_id)
    depfile = (os.path.join(self._depfile_dir, compilation_id) + '.dependencies')
    analysis_cache = (os.path.join(self._analysis_cache_dir, compilation_id) + '.analysis_cache')
    safe_mkdir(output_dir)
    if (not versioned_target_set.valid):
        with self.check_artifact_cache(versioned_target_set, build_artifacts=[output_dir, depfile, analysis_cache]) as in_cache:
            if (not in_cache):
                self.context.log.info(('Compiling targets %s' % versioned_target_set.targets))
                sources_by_target = self.calculate_sources(versioned_target_set.targets)
                if sources_by_target:
                    sources = reduce((lambda all, sources: all.union(sources)), sources_by_target.values())
                    if (not sources):
                        touch(depfile)
                        touch(analysis_cache)
                        self.context.log.warn(('Skipping scala compile for targets with no sources:\n  %s' % '\n  '.join((str(t) for t in sources_by_target.keys()))))
                    else:
                        classpath = [jar for (conf, jar) in cp if (conf in self._confs)]
                        result = self.compile(classpath, sources, output_dir, analysis_cache, upstream_analysis_caches, depfile)
                        if (result != 0):
                            raise TaskError(('%s returned %d' % (self._main, result)))
    if self.context.products.isrequired('classes'):
        self.context.log.debug(('Reading dependencies from ' + depfile))
        deps = Dependencies(output_dir)
        deps.load(depfile)
        genmap = self.context.products.get('classes')
        for (target, classes_by_source) in deps.findclasses(versioned_target_set.targets).items():
            for (source, classes) in classes_by_source.items():
                genmap.add(source, output_dir, classes)
                genmap.add(target, output_dir, classes)
        for target in versioned_target_set.targets:
            if (is_scalac_plugin(target) and target.classname):
                basedir = self.write_plugin_info(target)
                genmap.add(target, basedir, [_PLUGIN_INFO_FILE])
    analysis_cache_parts = os.path.split(analysis_cache)
    if (not upstream_analysis_caches.has(output_dir)):
        upstream_analysis_caches.add(output_dir, analysis_cache_parts[0], [analysis_cache_parts[1]])
    with self.context.state('classpath', []) as cp:
        for conf in self._confs:
            cp.insert(0, (conf, output_dir))
