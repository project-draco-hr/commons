def post_process(self, vt, upstream_analysis_caches, split_artifact):
    (output_dir, depfile, analysis_cache) = self.create_output_paths(vt.targets)
    if (not self.dry_run):
        if (self.context.products.isrequired('classes') and os.path.exists(depfile)):
            self.context.log.debug(('Reading dependencies from ' + depfile))
            deps = Dependencies(output_dir)
            deps.load(depfile)
            if split_artifact:
                self.split_artifact(deps, vt)
            genmap = self.context.products.get('classes')
            for (target, classes_by_source) in deps.findclasses(vt.targets).items():
                for (source, classes) in classes_by_source.items():
                    genmap.add(source, output_dir, classes)
                    genmap.add(target, output_dir, classes)
            for target in vt.targets:
                if (is_scalac_plugin(target) and target.classname):
                    basedir = self.write_plugin_info(target)
                    genmap.add(target, basedir, [_PLUGIN_INFO_FILE])
    if os.path.exists(analysis_cache):
        analysis_cache_parts = os.path.split(analysis_cache)
        if (not upstream_analysis_caches.has(output_dir)):
            upstream_analysis_caches.add(output_dir, analysis_cache_parts[0], [analysis_cache_parts[1]])
    with self.context.state('classpath', []) as cp:
        for conf in self._confs:
            cp.insert(0, (conf, output_dir))
