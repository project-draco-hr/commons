def execute(self, targets):
    scala_targets = filter((lambda t: has_sources(t, '.scala')), targets)
    if (not scala_targets):
        return
    egroups = self.context.products.get_data('exclusives_groups')
    group_id = egroups.get_group_key_for_target(scala_targets[0])
    for conf in self._confs:
        egroups.update_compatible_classpaths(group_id, [(conf, self._resources_dir)])
    cp = egroups.get_classpath_for_group(group_id)
    for conf in self._confs:
        for jar in self._zinc_utils.plugin_jars():
            cp.insert(0, (conf, jar))
    with self.invalidated(scala_targets, invalidate_dependents=True, partition_size_hint=self._partition_size_hint) as invalidation_check:
        if (invalidation_check.invalid_vts and (not self.dry_run)):
            invalid_targets = [vt.target for vt in invalidation_check.invalid_vts]
            invalid_sources_by_target = self._compute_sources_by_target(invalid_targets)
            invalid_sources = list(itertools.chain.from_iterable(invalid_sources_by_target.values()))
            deleted_sources = self._get_deleted_sources()
            self._ensure_analysis_tmpdir()
            tmpdir = os.path.join(self._analysis_tmpdir, str(uuid.uuid4()))
            os.mkdir(tmpdir)
            valid_analysis_tmp = os.path.join(tmpdir, 'valid_analysis')
            newly_invalid_analysis_tmp = os.path.join(tmpdir, 'newly_invalid_analysis')
            invalid_analysis_tmp = os.path.join(tmpdir, 'invalid_analysis')
            if ZincUtils.is_nonempty_analysis(self._analysis_file):
                with self.context.new_workunit(name='prepare-analysis'):
                    Analysis.split_to_paths(self._analysis_file, [((invalid_sources + deleted_sources), newly_invalid_analysis_tmp)], valid_analysis_tmp)
                    if ZincUtils.is_nonempty_analysis(self._invalid_analysis_file):
                        Analysis.merge_from_paths([self._invalid_analysis_file, newly_invalid_analysis_tmp], invalid_analysis_tmp)
                    else:
                        invalid_analysis_tmp = newly_invalid_analysis_tmp
                    shutil.move(valid_analysis_tmp, self._analysis_file)
                    shutil.move(invalid_analysis_tmp, self._invalid_analysis_file)
            partitions = []
            for vts in invalidation_check.invalid_vts_partitioned:
                partition_tmpdir = os.path.join(tmpdir, Target.maybe_readable_identify(vts.targets))
                os.mkdir(partition_tmpdir)
                sources = list(itertools.chain.from_iterable([invalid_sources_by_target.get(t, []) for t in vts.targets]))
                analysis_file = os.path.join(partition_tmpdir, 'analysis')
                partitions.append((vts, sources, analysis_file))
            if (ZincUtils.is_nonempty_analysis(self._invalid_analysis_file) and partitions):
                with self.context.new_workunit(name='partition-analysis'):
                    splits = [(x[1], x[2]) for x in partitions]
                    Analysis.split_to_paths(self._invalid_analysis_file, splits)
            for partition in partitions:
                (vts, sources, analysis_file) = partition
                self._process_target_partition(partition, cp)
                if os.path.exists(analysis_file):
                    new_valid_analysis = (analysis_file + '.valid.new')
                    if ZincUtils.is_nonempty_analysis(self._analysis_file):
                        with self.context.new_workunit(name='update-upstream-analysis'):
                            Analysis.merge_from_paths([self._analysis_file, analysis_file], new_valid_analysis)
                    else:
                        shutil.copy(analysis_file, new_valid_analysis)
                    shutil.move(new_valid_analysis, self._analysis_file)
                    actual_deps = Analysis.parse_deps_from_path(self._analysis_file)
                    actual_deps_filtered = {}
                    scalalib_re = re.compile('scala-library-\\d+\\.\\d+\\.\\d+\\.jar$')
                    for (src, deps) in actual_deps.iteritems():
                        actual_deps_filtered[src] = filter((lambda x: (scalalib_re.search(x) is None)), deps)
                    self.check_for_missing_dependencies(sources, actual_deps_filtered)
                    if self.artifact_cache_writes_enabled():
                        self._write_to_artifact_cache(analysis_file, vts, invalid_sources_by_target)
                if ZincUtils.is_nonempty_analysis(self._invalid_analysis_file):
                    with self.context.new_workunit(name='trim-downstream-analysis'):
                        new_invalid_analysis = (analysis_file + '.invalid.new')
                        discarded_invalid_analysis = (analysis_file + '.invalid.discard')
                        Analysis.split_to_paths(self._invalid_analysis_file, [(sources, discarded_invalid_analysis)], new_invalid_analysis)
                        shutil.move(new_invalid_analysis, self._invalid_analysis_file)
                vts.update()
    if self.context.products.isrequired('classes'):
        sources_by_target = self._compute_sources_by_target(scala_targets)
        classes_by_source = self._compute_classes_by_source()
        self._add_all_products_to_genmap(sources_by_target, classes_by_source)
    for conf in self._confs:
        egroups.update_compatible_classpaths(group_id, [(conf, self._classes_dir)])
