def execute(self, targets):
    scala_targets = filter(_is_scala, targets)
    if (not scala_targets):
        return
    with self.context.state('classpath', []) as cp:
        self._add_globally_required_classpath_entries(cp)
        with self.context.state('upstream_analysis_map', {}) as upstream_analysis_map:
            with self.invalidated(scala_targets, invalidate_dependents=True, partition_size_hint=self._partition_size_hint) as invalidation_check:
                for vts in invalidation_check.all_vts_partitioned:
                    if (not self.dry_run):
                        merged_artifact = self._process_target_partition(vts, cp, upstream_analysis_map)
                        vts.update()
                        if os.path.exists(merged_artifact.classes_dir):
                            for conf in self._confs:
                                cp.append((conf, merged_artifact.classes_dir))
                            if os.path.exists(merged_artifact.analysis_file):
                                upstream_analysis_map[merged_artifact.classes_dir] = AnalysisFileSpec(merged_artifact.analysis_file, merged_artifact.classes_dir)
    all_analysis_files = set()
    for target in scala_targets:
        analysis_file_spec = self._artifact_factory.analysis_file_for_targets([target])
        if os.path.exists(analysis_file_spec.analysis_file):
            all_analysis_files.add(analysis_file_spec)
    deps_cache = JvmDependencyCache(self.context, scala_targets, all_analysis_files)
    deps_cache.check_undeclared_dependencies()
