def parse_header(self):
    lines = filter((lambda x: (not AUTHOR_RE.match(x))), self._old_lines)
    try:
        p = next((i for (i, line) in enumerate(lines) if (line and (not line.startswith(u'#')))))
    except StopIteration:
        return
    content_lines = lines[p:]

    def add_import(imp):
        s = imp.package()
        if (s.split(u'.', 1)[0] in KNOWN_STD_LIBS):
            self._stdlib_imports.append(imp)
        elif s.startswith(NEW_PANTS_PACKAGE):
            self._pants_imports.append(imp)
        else:
            self._thirdparty_imports.append(imp)

    def is_import(line):
        m = IMPORT_RE.match(line)
        if m:
            add_import(Import(m.group(1)))
            return True
        else:
            return False

    def is_from_import(line):

        def absify(imp):
            if (imp == u'.'):
                return self._package
            elif imp.startswith(u'.'):
                return ((u'%s.' % self._package) + imp[1:])
            else:
                return imp
        m = FROM_IMPORT_RE.match(line)
        if m:
            if (not (m.group(1) == u'__future__')):
                add_import(FromImport(absify(m.group(1)), m.group(2).split(u',')))
            return True
        else:
            return False
    lines_iter = iter(content_lines)
    line = u''
    line_parts = []
    try:
        while ((not line) or is_import(line) or is_from_import(line)):
            line_parts = [lines_iter.next()]
            while has_continuation(line_parts[(-1)]):
                line_parts.append(lines_iter.next())
            line = u' '.join(([x[:(-1)].strip() for x in line_parts[:(-1)]] + [line_parts[(-1)].strip()]))
    except StopIteration:
        line_parts = []

    def translate(line):
        return line.replace(u'twitter/pants', u'pants').replace(u'twitter.pants', u'pants')
    self._body = map(translate, (([u''] + line_parts) + list(lines_iter)))
    while (self._body and (not self._body[(-1)])):
        self._body = self._body[0:(-1)]
