def test_crawler_local():
    FL = ('a.txt', 'b.txt', 'c.txt')
    with temporary_dir() as td:
        for fn in FL:
            with open(os.path.join(td, fn), 'w') as fp:
                pass
        for dn in (1, 2):
            os.mkdir(os.path.join(td, ('dir%d' % dn)))
            for fn in FL:
                with open(os.path.join(td, ('dir%d' % dn), fn), 'w') as fp:
                    pass
        (links, rels) = Crawler(enable_cache=False).execute(td)
        assert (set(links) == set((os.path.join(td, fn) for fn in FL)))
        assert (set(rels) == set((os.path.join(td, ('dir%d' % n)) for n in (1, 2))))
        for caching in (False, True):
            for threads in (1, 2, 3):
                links = Crawler(enable_cache=caching, threads=threads).crawl([td], follow_links=True)
                expect_links = ((set((os.path.join(td, fn) for fn in FL)) | set((os.path.join(td, 'dir1', fn) for fn in FL))) | set((os.path.join(td, 'dir2', fn) for fn in FL)))
                assert (set(links) == expect_links)
