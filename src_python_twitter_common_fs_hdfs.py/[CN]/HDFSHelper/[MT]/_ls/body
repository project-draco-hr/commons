def _ls(self, path, is_dir=False, is_recursive=False):
    '\n    Return list of [hdfs_full_path, filesize]\n    Raises exception when the hadoop ls command returns error\n    '
    hdfs_cmd = ('-lsr' if is_recursive else '-ls')
    (exit_code, ls_result) = self._call(hdfs_cmd, path, return_output=True)
    if (exit_code != 0):
        raise self.InternalError(('Error occurred. %s.Check logs for details' % ls_result))
    file_list = []
    if (ls_result == None):
        return file_list
    lines = ls_result.splitlines()
    for line in lines:
        if ((line == '') or line.startswith('Found')):
            continue
        seg = line.split(None, 7)
        if (len(seg) < 8):
            raise self.InternalError(('Invalid hdfs -ls output. [%s]' % line))
        filename = seg[(-1)]
        try:
            metadata = self.PARSER.parse(' '.join(seg[0:7]))
        except ScanfParser.ParseError as e:
            raise self.InternalError(('Unable to parse hdfs output: %s' % e))
        if (metadata.mode.startswith('d') != is_dir):
            continue
        file_list.append([filename, metadata.filesize])
    return file_list
